#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Script to merge metrics.json files from multiple simulation study directories
generated by simulation_study.py into a single CSV or Parquet file.
"""

import argparse
import json
from pathlib import Path
import pandas as pd
import sys
from typing import List, Dict, Optional

def find_metrics_files(base_dir: Path, study_pattern: str, metrics_filename: str) -> List[Path]:
    """
    Finds all metrics files within study directories matching the pattern.

    Args:
        base_dir: The directory containing the study_* folders.
        study_pattern: Glob pattern for study directories (e.g., "study_*").
        metrics_filename: Name of the metrics file (e.g., "metrics.json").

    Returns:
        A list of Path objects pointing to the found metrics files.
    """
    metrics_files = []
    print(f"Searching for study directories matching '{study_pattern}' in '{base_dir}'...")
    study_dirs = list(base_dir.glob(study_pattern))
    print(f"Found {len(study_dirs)} potential study directories.")

    if not study_dirs:
        print("Warning: No study directories found matching the pattern.")
        return []

    for study_dir in study_dirs:
        if not study_dir.is_dir():
            continue
        print(f"  Scanning study directory: {study_dir.name}")
        # Recursively search for the metrics file within each study directory
        # Assumes structure: base_dir/study_*/config_*/metrics.json
        found_in_study = list(study_dir.rglob(f"*/{metrics_filename}"))
        if found_in_study:
            print(f"    Found {len(found_in_study)} '{metrics_filename}' files in {study_dir.name}.")
            metrics_files.extend(found_in_study)
        else:
             print(f"    No '{metrics_filename}' files found in {study_dir.name}.")


    return metrics_files

def load_metric(file_path: Path, study_id: str) -> Optional[Dict]:
    """
    Loads a single metrics JSON file and adds the study ID.

    Args:
        file_path: Path to the metrics.json file.
        study_id: The name of the parent study directory.

    Returns:
        A dictionary containing the metrics data and the study_id,
        or None if an error occurs.
    """
    try:
        with open(file_path, 'r') as f:
            data = json.load(f)
        data['study_id'] = study_id # Add the study identifier
        # Add the specific run label as well for more granular identification
        data['run_label'] = file_path.parent.name # Assumes parent dir is the run label
        return data
    except json.JSONDecodeError as e:
        print(f"Error decoding JSON from {file_path}: {e}")
        return None
    except Exception as e:
        print(f"Error reading file {file_path}: {e}")
        return None

def main():
    # --- Argument Parsing ---
    parser = argparse.ArgumentParser(
        description="Merge metrics.json files from multiple simulation study directories.",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument(
        "--input-dir",
        type=Path,
        required=True,
        help="Directory containing the study_* folders (e.g., simulation_results_raw)."
    )
    parser.add_argument(
        "--output-file",
        type=Path,
        required=True,
        help="Path to save the merged metrics (e.g., merged_metrics.csv or merged_metrics.parquet)."
    )
    parser.add_argument(
        "--study-pattern",
        default="study_*",
        help="Glob pattern for identifying study directories within the input directory."
    )
    parser.add_argument(
        "--metrics-filename",
        default="metrics.json",
        help="Name of the metrics file to search for within each run's subdirectory."
    )
    args = parser.parse_args()

    # --- Input Validation ---
    if not args.input_dir.is_dir():
        print(f"Error: Input directory not found: {args.input_dir}")
        sys.exit(1)

    output_suffix = args.output_file.suffix.lower()
    if output_suffix not in [".csv", ".parquet"]:
        print(f"Error: Output file must have a .csv or .parquet extension. Found: {output_suffix}")
        sys.exit(1)

    if output_suffix == ".parquet":
        try:
            import pyarrow
            print(f"PyArrow version: {pyarrow.__version__}") # Verify import
        except ImportError:
            print("Error: 'pyarrow' package is required to save in Parquet format.")
            print("Install it using: pip install pyarrow or uv pip install pyarrow")
            sys.exit(1)

    # --- Find and Load Metrics ---
    metrics_files = find_metrics_files(args.input_dir, args.study_pattern, args.metrics_filename)
    print(f"\nFound {len(metrics_files)} total '{args.metrics_filename}' files across all studies.")

    all_metrics_data = []
    processed_count = 0
    error_count = 0
    for file_path in metrics_files:
        # Determine study_id based on the path relative to input_dir
        try:
            relative_path = file_path.relative_to(args.input_dir)
            # The first part of the relative path should be the study directory
            study_id = relative_path.parts[0]
        except ValueError:
             print(f"Warning: Could not determine study_id for {file_path}. Skipping.")
             error_count += 1
             continue

        metric_data = load_metric(file_path, study_id)
        if metric_data:
            all_metrics_data.append(metric_data)
            processed_count += 1
        else:
            error_count += 1

    print(f"\nSuccessfully processed {processed_count} metrics files.")
    if error_count > 0:
        print(f"Warning: Failed to process or determine study ID for {error_count} files (check logs above).")

    # --- Create and Save DataFrame ---
    if not all_metrics_data:
        print("No metrics data successfully loaded to merge. Exiting.")
        sys.exit(0)

    print("\nCreating DataFrame...")
    try:
        df = pd.DataFrame(all_metrics_data)

        # Optional: Reorder columns for clarity - put identifiers first
        id_cols = ['study_id', 'run_label']
        other_cols = [col for col in df.columns if col not in id_cols]
        # Handle case where 'run_label' might not exist if load_metric failed partially
        final_id_cols = [col for col in id_cols if col in df.columns]
        df = df[final_id_cols + other_cols]

    except Exception as e:
        print(f"Error creating DataFrame: {e}")
        # Consider printing some of the problematic data if possible
        # print("Sample data causing issues:", all_metrics_data[:5])
        sys.exit(1)


    print(f"Saving merged data ({len(df)} rows) to '{args.output_file}'...")
    try:
        # Ensure output directory exists
        args.output_file.parent.mkdir(parents=True, exist_ok=True)

        if output_suffix == ".csv":
            df.to_csv(args.output_file, index=False)
        elif output_suffix == ".parquet":
            # Consider compression options if needed: compression='snappy' or 'gzip'
            df.to_parquet(args.output_file, index=False, engine='pyarrow')
        print("Save complete.")
    except Exception as e:
        print(f"Error saving output file '{args.output_file}': {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()